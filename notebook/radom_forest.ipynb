{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09099fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'ISO-8859-1', 'confidence': 0.728467, 'language': ''}\n",
      "                                               Tweet  HS  Abusive  \\\n",
      "0  - disaat semua cowok berusaha melacak perhatia...   1        1   \n",
      "1  RT USER: USER siapa yang telat ngasih tau elu?...   0        1   \n",
      "2  41. Kadang aku berfikir, kenapa aku tetap perc...   0        0   \n",
      "3  USER USER AKU ITU AKU\\n\\nKU TAU MATAMU SIPIT T...   0        0   \n",
      "4  USER USER Kaum cebong kapir udah keliatan dong...   1        1   \n",
      "\n",
      "   HS_Individual  HS_Group  HS_Religion  HS_Race  HS_Physical  HS_Gender  \\\n",
      "0              1         0            0        0            0          0   \n",
      "1              0         0            0        0            0          0   \n",
      "2              0         0            0        0            0          0   \n",
      "3              0         0            0        0            0          0   \n",
      "4              0         1            1        0            0          0   \n",
      "\n",
      "   HS_Other  HS_Weak  HS_Moderate  HS_Strong  \n",
      "0         1        1            0          0  \n",
      "1         0        0            0          0  \n",
      "2         0        0            0          0  \n",
      "3         0        0            0          0  \n",
      "4         0        0            1          0  \n",
      "Index(['Tweet', 'HS', 'Abusive', 'HS_Individual', 'HS_Group', 'HS_Religion',\n",
      "       'HS_Race', 'HS_Physical', 'HS_Gender', 'HS_Other', 'HS_Weak',\n",
      "       'HS_Moderate', 'HS_Strong'],\n",
      "      dtype='object')\n",
      "Index(['Tweet', 'HS', 'Abusive', 'HS_Individual', 'HS_Group', 'HS_Religion',\n",
      "       'HS_Race', 'HS_Physical', 'HS_Gender', 'HS_Other', 'HS_Weak',\n",
      "       'HS_Moderate', 'HS_Strong'],\n",
      "      dtype='object')\n",
      "\n",
      "=== Evaluasi untuk label: HS ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.91      0.87      1516\n",
      "           1       0.86      0.76      0.81      1118\n",
      "\n",
      "    accuracy                           0.85      2634\n",
      "   macro avg       0.85      0.84      0.84      2634\n",
      "weighted avg       0.85      0.85      0.84      2634\n",
      "\n",
      "Akurasi: 0.8462\n",
      "\n",
      "=== Evaluasi untuk label: Abusive ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      1646\n",
      "           1       0.91      0.82      0.86       988\n",
      "\n",
      "    accuracy                           0.90      2634\n",
      "   macro avg       0.90      0.89      0.89      2634\n",
      "weighted avg       0.90      0.90      0.90      2634\n",
      "\n",
      "Akurasi: 0.9032\n",
      "\n",
      "=== Evaluasi untuk label: HS_Individual ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.89      1916\n",
      "           1       0.76      0.54      0.63       718\n",
      "\n",
      "    accuracy                           0.83      2634\n",
      "   macro avg       0.80      0.74      0.76      2634\n",
      "weighted avg       0.82      0.83      0.82      2634\n",
      "\n",
      "Akurasi: 0.8265\n",
      "\n",
      "=== Evaluasi untuk label: HS_Group ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94      2234\n",
      "           1       0.76      0.36      0.49       400\n",
      "\n",
      "    accuracy                           0.89      2634\n",
      "   macro avg       0.83      0.67      0.71      2634\n",
      "weighted avg       0.88      0.89      0.87      2634\n",
      "\n",
      "Akurasi: 0.8861\n",
      "\n",
      "=== Evaluasi untuk label: HS_Religion ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      2470\n",
      "           1       0.87      0.32      0.47       164\n",
      "\n",
      "    accuracy                           0.95      2634\n",
      "   macro avg       0.91      0.66      0.72      2634\n",
      "weighted avg       0.95      0.95      0.94      2634\n",
      "\n",
      "Akurasi: 0.9548\n",
      "\n",
      "=== Evaluasi untuk label: HS_Race ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2516\n",
      "           1       0.88      0.47      0.62       118\n",
      "\n",
      "    accuracy                           0.97      2634\n",
      "   macro avg       0.93      0.74      0.80      2634\n",
      "weighted avg       0.97      0.97      0.97      2634\n",
      "\n",
      "Akurasi: 0.9734\n",
      "\n",
      "=== Evaluasi untuk label: HS_Physical ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2581\n",
      "           1       0.73      0.15      0.25        53\n",
      "\n",
      "    accuracy                           0.98      2634\n",
      "   macro avg       0.86      0.57      0.62      2634\n",
      "weighted avg       0.98      0.98      0.98      2634\n",
      "\n",
      "Akurasi: 0.9818\n",
      "\n",
      "=== Evaluasi untuk label: HS_Gender ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2580\n",
      "           1       1.00      0.09      0.17        54\n",
      "\n",
      "    accuracy                           0.98      2634\n",
      "   macro avg       0.99      0.55      0.58      2634\n",
      "weighted avg       0.98      0.98      0.97      2634\n",
      "\n",
      "Akurasi: 0.9814\n",
      "\n",
      "=== Evaluasi untuk label: HS_Other ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90      1873\n",
      "           1       0.82      0.62      0.71       761\n",
      "\n",
      "    accuracy                           0.85      2634\n",
      "   macro avg       0.84      0.78      0.80      2634\n",
      "weighted avg       0.85      0.85      0.84      2634\n",
      "\n",
      "Akurasi: 0.8516\n",
      "\n",
      "=== Evaluasi untuk label: HS_Weak ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      1964\n",
      "           1       0.74      0.48      0.58       670\n",
      "\n",
      "    accuracy                           0.82      2634\n",
      "   macro avg       0.79      0.71      0.74      2634\n",
      "weighted avg       0.82      0.82      0.81      2634\n",
      "\n",
      "Akurasi: 0.8246\n",
      "\n",
      "=== Evaluasi untuk label: HS_Moderate ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.93      2282\n",
      "           1       0.69      0.20      0.31       352\n",
      "\n",
      "    accuracy                           0.88      2634\n",
      "   macro avg       0.79      0.59      0.62      2634\n",
      "weighted avg       0.86      0.88      0.85      2634\n",
      "\n",
      "Akurasi: 0.8808\n",
      "\n",
      "=== Evaluasi untuk label: HS_Strong ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2538\n",
      "           1       0.81      0.52      0.63        96\n",
      "\n",
      "    accuracy                           0.98      2634\n",
      "   macro avg       0.89      0.76      0.81      2634\n",
      "weighted avg       0.98      0.98      0.98      2634\n",
      "\n",
      "Akurasi: 0.9780\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import chardet\n",
    "\n",
    "# %%\n",
    "# Deteksi encoding file CSV\n",
    "with open('../data/data.csv', 'rb') as f:\n",
    "    result = chardet.detect(f.read(10000))  # Baca 10KB pertama\n",
    "    print(result)\n",
    "\n",
    "# Baca data dengan encoding hasil deteksi\n",
    "df = pd.read_csv('../data/data.csv', encoding=result['encoding'], header=0)\n",
    "print(df.head())\n",
    "print(df.columns)\n",
    "df.head()\n",
    "\n",
    "# %%\n",
    "print(df.columns)\n",
    "\n",
    "# %%\n",
    "# Fitur (Tweet) dan target (semua label multilabel)\n",
    "X = df['Tweet']\n",
    "y = df[['HS', 'Abusive', 'HS_Individual', 'HS_Group', 'HS_Religion', 'HS_Race', \n",
    "        'HS_Physical', 'HS_Gender', 'HS_Other', 'HS_Weak', 'HS_Moderate', 'HS_Strong']]\n",
    "\n",
    "# %%\n",
    "# Daftar stopword bahasa Indonesia manual\n",
    "stopwords_indonesia = [\n",
    "    'yang', 'dan', 'di', 'ke', 'dari', 'ini', 'itu', 'untuk', 'pada', 'dengan', \n",
    "    'adalah', 'atau', 'juga', 'sebagai', 'karena', 'oleh', 'tidak', 'sudah',\n",
    "    'saja', 'maka', 'lagi', 'bagi', 'namun', 'setelah', 'sebelum', 'hingga', \n",
    "    'tersebut', 'setiap', 'kami', 'kita', 'mereka', 'aku', 'saya', 'anda', \n",
    "    'engkau', 'dia', 'ia', 'kalian', 'jadi', 'apakah', 'dimana', 'kapan',\n",
    "    'mengapa', 'bagaimana', 'bahwa', 'tentang'\n",
    "]\n",
    "\n",
    "# TF-IDF Vectorizer dengan stopword bahasa Indonesia manual\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords_indonesia, max_features=5000)\n",
    "\n",
    "# Transform X\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# %%\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# %%\n",
    "# Model Random Forest multilabel\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "multi_rf = MultiOutputClassifier(rf)\n",
    "multi_rf.fit(X_train, y_train)\n",
    "\n",
    "# %%\n",
    "# Prediksi\n",
    "y_pred = multi_rf.predict(X_test)\n",
    "\n",
    "# %%\n",
    "# Evaluasi per label\n",
    "for i, column in enumerate(y.columns):\n",
    "    print(f\"\\n=== Evaluasi untuk label: {column} ===\")\n",
    "    print(classification_report(y_test.iloc[:, i], y_pred[:, i]))\n",
    "    print(f\"Akurasi: {accuracy_score(y_test.iloc[:, i], y_pred[:, i]):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53a1fc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Teks: Saya sangat tidak suka dengan perlakuan ini, ini adalah kebencian ras!\n",
      "Probabilitas prediksi per label:\n",
      "  HS: 0.160\n",
      "  Abusive: 0.210\n",
      "  HS_Individual: 0.140\n",
      "  HS_Group: 0.380\n",
      "  HS_Religion: 0.010\n",
      "  HS_Race: 0.110\n",
      "  HS_Physical: 0.000\n",
      "  HS_Gender: 0.000\n",
      "  HS_Other: 0.090\n",
      "  HS_Weak: 0.140\n",
      "  HS_Moderate: 0.350\n",
      "  HS_Strong: 0.000\n",
      "\n",
      "Teks: Ayo kita dukung perdamaian dan toleransi antar umat beragama\n",
      "Probabilitas prediksi per label:\n",
      "  HS: 0.130\n",
      "  Abusive: 0.010\n",
      "  HS_Individual: 0.100\n",
      "  HS_Group: 0.090\n",
      "  HS_Religion: 0.140\n",
      "  HS_Race: 0.000\n",
      "  HS_Physical: 0.010\n",
      "  HS_Gender: 0.000\n",
      "  HS_Other: 0.050\n",
      "  HS_Weak: 0.030\n",
      "  HS_Moderate: 0.010\n",
      "  HS_Strong: 0.040\n",
      "\n",
      "Teks: Orang itu kasar dan menyerang secara fisik\n",
      "Probabilitas prediksi per label:\n",
      "  HS: 0.130\n",
      "  Abusive: 0.070\n",
      "  HS_Individual: 0.170\n",
      "  HS_Group: 0.010\n",
      "  HS_Religion: 0.080\n",
      "  HS_Race: 0.000\n",
      "  HS_Physical: 0.000\n",
      "  HS_Gender: 0.050\n",
      "  HS_Other: 0.190\n",
      "  HS_Weak: 0.150\n",
      "  HS_Moderate: 0.040\n",
      "  HS_Strong: 0.000\n",
      "\n",
      "Teks: Ini hanyalah pendapat saya, tidak bermaksud menghina siapapun\n",
      "Probabilitas prediksi per label:\n",
      "  HS: 0.050\n",
      "  Abusive: 0.050\n",
      "  HS_Individual: 0.030\n",
      "  HS_Group: 0.030\n",
      "  HS_Religion: 0.050\n",
      "  HS_Race: 0.000\n",
      "  HS_Physical: 0.000\n",
      "  HS_Gender: 0.020\n",
      "  HS_Other: 0.010\n",
      "  HS_Weak: 0.100\n",
      "  HS_Moderate: 0.040\n",
      "  HS_Strong: 0.000\n"
     ]
    }
   ],
   "source": [
    "# import library penting (anggap sebelumnya sudah training model)\n",
    "import pandas as pd\n",
    "\n",
    "# Contoh kalimat baru yang ingin kita prediksi labelnya\n",
    "sample_texts = [\n",
    "    \"Saya sangat tidak suka dengan perlakuan ini, ini adalah kebencian ras!\",\n",
    "    \"Ayo kita dukung perdamaian dan toleransi antar umat beragama\",\n",
    "    \"Orang itu kasar dan menyerang secara fisik\",\n",
    "    \"Ini hanyalah pendapat saya, tidak bermaksud menghina siapapun\"\n",
    "]\n",
    "\n",
    "# Transform teks baru pakai vectorizer yang sudah fit sebelumnya\n",
    "X_new_tfidf = vectorizer.transform(sample_texts)\n",
    "\n",
    "# Mendapatkan probabilitas prediksi untuk teks baru (hanya untuk RandomForestClassifier yang mendukung)\n",
    "y_new_proba = multi_rf.predict_proba(X_new_tfidf)\n",
    "\n",
    "for i, text in enumerate(sample_texts):\n",
    "    print(f\"\\nTeks: {text}\")\n",
    "    print(\"Probabilitas prediksi per label:\")\n",
    "    for label, prob in zip(y.columns, [prob[i][1] for prob in y_new_proba]):\n",
    "        print(f\"  {label}: {prob:.3f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
